{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks for @cointegrated - author of https://habrahabr.ru/post/346198/ \n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_by_id(pid):\n",
    "    \"\"\" Download and parse an article from postimees.ee \"\"\"\n",
    "    # downloading\n",
    "    r = requests.get('https://postimees.ee/' +str(pid) + '/')\n",
    "    # parsing\n",
    "    soup = BeautifulSoup(r.text, 'html5lib')\n",
    "    doc = {}\n",
    "    doc['id'] = pid\n",
    "    if (soup.title.text[:3]=='404') or \\\n",
    "        ((soup.find(\"html\", attrs={'lang':'ru'})==None) and (soup.find(\"html\", attrs={'lang':'et'})==None)) or \\\n",
    "        soup.find(\"div\", attrs={'class':'saadetud_sobrale_onclick'})!=None or \\\n",
    "        soup.find(\"div\", attrs={'id':'kaart_area'})!=None or \\\n",
    "        soup.find(\"span\", attrs={'id':'scrollDown'})!=None or \\\n",
    "        soup.find(\"section\", attrs={'id':'fullScreenImage'})!=None or \\\n",
    "        soup.find(\"span\", attrs={'class':'header-logo__section slab'})!=None or \\\n",
    "        soup.find(\"div\", attrs={'class':'article-lead__item'})!=None:\n",
    "        # These are the exceptions that I've got from the experience - special editions and so on\n",
    "        # Unfortunately I did not find any special features of that pages in html\n",
    "        doc['status'] = 'title_not_found'\n",
    "    else:\n",
    "        doc['status'] = 'ok'\n",
    "        \n",
    "        if soup.find(\"html\", attrs={'lang':'ru'})!=None:\n",
    "            doc['lang']='ru'\n",
    "        else:\n",
    "            doc['lang']='et'\n",
    "\n",
    "        doc['title'] = soup.find(\"meta\", property=\"og:title\")[\"content\"]   # Title\n",
    "        text=''\n",
    "        for i in soup.find_all('p',attrs={'class':''}):\n",
    "            text = text + i.text + \" \"\n",
    "        doc['text'] = text # Text from a few paragraphs\n",
    "        doc['theme'] = soup.find(\"meta\", property=\"article:section\")[\"content\"] # Theme\n",
    "        doc['keywords'] = soup.find(\"meta\", attrs={'name':'keywords'})['content'] # Keywords\n",
    "        doc['time'] = soup.find(\"meta\", property=\"article:modified_time\")[\"content\"].replace('+02:00','') # Date and time\n",
    "        comcount = soup.find(\"span\", attrs={'class':'article-comment-count'})\n",
    "        doc['comcount'] = 0 if comcount==None else comcount.text  # Count of comments\n",
    "        autor = soup.find(\"a\", attrs={'class':'article-author__link'})\n",
    "        doc['autor']=0 if autor==None else autor.text  # Author\n",
    "        doc['full_url'] = '' if soup.find(\"link\", attrs={'rel':'canonical'})==None \\\n",
    "                                else soup.find(\"link\", attrs={'rel':'canonical'})['href']  \n",
    "            # Full url, because I use a short url and we have redirecting after this. The first part of the full url \n",
    "            # may be used for categorization\n",
    "    \n",
    "    # Save file with result dictionary\n",
    "    fname = r'files/' + str(pid) + '.pkl'\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    p = Pool(1) # Did not work on my computer\n",
    "#    docs = p.map(get_doc_by_id, np.arange(4367958,4367961))\n",
    "counter = 0\n",
    "for i in list(range(4250000,4372719)):  # From 20.09.2017 to 12.01.2018\n",
    "    counter += 1\n",
    "    if counter%200==0: # Sleep I use because there is blocking on postimees.ee.\n",
    "        time.sleep(5)\n",
    "    elif counter == 4999:\n",
    "        time.sleep(180)\n",
    "        counter = 0\n",
    "    get_art_by_id(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
